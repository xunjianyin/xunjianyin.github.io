<!DOCTYPE HTML>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>EAMA: Entity-Aware Multimodal Alignment for News Image Captioning</title>
  <link rel="stylesheet" type="text/css" href="../stylesheet.css">
  <link rel="stylesheet" type="text/css" href="../shared-styles.css">
  <link rel="icon" type="image/png" href="../figures/logo.png">
  <style>
    .paper-container { max-width: 850px; margin: 0 auto; padding: 40px 20px; line-height: 1.8; }
    .paper-title { font-size: 32px; font-weight: bold; margin-bottom: 20px; line-height: 1.3; color: #1a1a1a; }
    .paper-authors { font-size: 16px; color: #555; margin-bottom: 8px; }
    .paper-venue { font-size: 15px; color: #888; margin-bottom: 25px; font-style: italic; }
    .paper-links { margin-bottom: 35px; }
    .paper-links a { display: inline-block; padding: 10px 20px; margin-right: 12px; margin-bottom: 10px; background: #2d5a3d; color: white; text-decoration: none; border-radius: 6px; font-size: 14px; font-weight: 500; transition: all 0.2s; }
    .paper-links a:hover { background: #1e3d2a; transform: translateY(-1px); }
    .story-section { margin-bottom: 35px; }
    .story-section h2 { font-size: 22px; color: #2d5a3d; margin-bottom: 15px; font-weight: 600; }
    .story-section p { color: #333; margin-bottom: 15px; text-align: justify; }
    .highlight-box { background: linear-gradient(135deg, #f8faf8 0%, #eef4ee 100%); padding: 25px 30px; border-radius: 10px; margin: 30px 0; border-left: 4px solid #2d5a3d; }
    .highlight-box h3 { margin-top: 0; color: #2d5a3d; font-size: 18px; }
    .highlight-box ul { margin-bottom: 0; padding-left: 20px; }
    .highlight-box li { margin-bottom: 8px; color: #444; }
    .back-link { margin-bottom: 30px; }
    .back-link a { color: #2d5a3d; text-decoration: none; font-weight: 500; font-size: 15px; }
    .back-link a:hover { text-decoration: underline; }
    .paper-citation { background: #f5f5f5; padding: 20px; border-radius: 8px; font-family: 'Monaco', 'Menlo', monospace; font-size: 12px; overflow-x: auto; white-space: pre-wrap; margin-top: 40px; }
    .paper-citation h3 { font-family: inherit; margin-top: 0; margin-bottom: 15px; font-size: 16px; color: #333; }

    /* Dark mode styles */
    [data-theme="dark"] .paper-title { color: var(--text-color); }
    [data-theme="dark"] .paper-authors { color: #b8b8b8; }
    [data-theme="dark"] .paper-venue { color: #999; }
    [data-theme="dark"] .story-section h2 { color: var(--primary-color); }
    [data-theme="dark"] .story-section p { color: var(--text-color); }
    [data-theme="dark"] .paper-figure figcaption { color: #b8b8b8; }
    [data-theme="dark"] .highlight-box { background: linear-gradient(135deg, #1a2a1a 0%, #1e3a1e 100%); border-left-color: var(--primary-color); }
    [data-theme="dark"] .highlight-box h3 { color: var(--primary-color); }
    [data-theme="dark"] .highlight-box li, [data-theme="dark"] .highlight-box p { color: var(--text-color); }
    [data-theme="dark"] .back-link a { color: var(--primary-color); }
    [data-theme="dark"] .paper-citation { background: var(--section-bg); color: var(--text-color); }
    [data-theme="dark"] .paper-links a { background: var(--primary-color); }
    [data-theme="dark"] .paper-links a:hover { background: #004a8c; }
  </style>
</head>
<body>
  <nav class="nav-buttons" role="navigation" aria-label="Main navigation">
    <a href="../index.html" class="nav-button">Home</a>
    <a href="../publications.html" class="nav-button">Publications</a>
    <a href="../projects.html" class="nav-button">Projects</a>
    <a href="../blogs.html" class="nav-button">Blogs</a>
    <a href="../photography.html" class="nav-button">Photography</a>
    <button id="theme-toggle" class="theme-toggle" aria-label="Toggle dark mode" title="Toggle dark/light mode"></button>
  </nav>

  <main class="paper-container">
    <div class="back-link"><a href="../index.html">&larr; Back to Home</a></div>

    <h1 class="paper-title">EAMA: Entity-Aware Multimodal Alignment Based Approach for News Image Captioning</h1>
    <p class="paper-authors">Junzhe Zhang, Huixuan Zhang, <b>Xunjian Yin</b>, Xiaojun Wan</p>
    <p class="paper-venue">TOMM 2025</p>

    <div class="paper-links">
      <a href="https://arxiv.org/abs/2402.19404">Paper</a>
    </div>

    <div class="story-section">
      <h2>The Entity Problem in News Captioning</h2>
      <p>News image captioning differs fundamentally from generic image captioning. A news photo of a press conference isn't just "a person speaking at a podium"—it's a specific politician, at a specific event, discussing a specific topic. Entities—people, organizations, locations—are the backbone of news captions.</p>
      <p>Multimodal large language models have made impressive strides across vision-language tasks, yet they struggle with this entity-rich setting. In zero-shot mode, they lack the contextual knowledge to name specific people or events. Even with fine-tuning, they often fail to ground entity information correctly across text and image modalities.</p>
    </div>

    <div class="story-section">
      <h2>Aligning Models to Entity Awareness</h2>
      <p>Rather than treating entity handling as an afterthought, EAMA builds entity awareness directly into the alignment process. We design two auxiliary tasks alongside the main captioning objective: <b>Entity-Aware Sentence Selection</b>, which trains the model to identify which sentences in an article are most relevant to a given image, and <b>Entity Selection</b>, which trains it to pick the correct entities associated with an image from candidates.</p>
      <p>These tasks force the model to develop a deeper understanding of how entities connect across visual and textual modalities—not just what appears in an image, but who and what it refers to in a broader news context.</p>
    </div>

    <div class="highlight-box">
      <h3>Self-Extracted Entity Information</h3>
      <p>A key insight of EAMA is that once aligned, the model itself can extract entity-related information to supplement its input during caption generation. There is no need for external entity recognition modules or knowledge bases—the aligned model serves as its own entity extractor, keeping the pipeline simple and end-to-end.</p>
    </div>

    <div class="story-section">
      <h2>Balancing Sufficiency and Conciseness</h2>
      <p>News captioning faces a tension: the model needs enough context to generate entity-rich captions, but too much input introduces noise and confusion. EAMA addresses this by letting the aligned model decide what information is relevant, naturally filtering the textual input to balance sufficiency and conciseness during generation.</p>
    </div>

    <div class="highlight-box">
      <h3>Key Results</h3>
      <ul>
        <li><b>State-of-the-Art Performance:</b> Superior results on both GoodNews and NYTimes800k benchmarks</li>
        <li><b>Better Entity Handling:</b> Improved named entity precision and recall over previous methods</li>
        <li><b>End-to-End Simplicity:</b> No external entity modules needed—the aligned model self-extracts entity information</li>
        <li><b>Effective Alignment:</b> Two auxiliary tasks significantly improve entity-aware multimodal understanding</li>
      </ul>
    </div>

    <div class="story-section">
      <h2>Toward Entity-Grounded Multimodal Understanding</h2>
      <p>EAMA demonstrates that targeted alignment tasks can address specific weaknesses in MLLMs. By designing training objectives that explicitly require entity reasoning across modalities, we bridge the gap between generic multimodal understanding and the entity-centric demands of news captioning. The approach points toward a broader principle: alignment tasks tailored to downstream challenges can unlock capabilities that general-purpose training leaves on the table.</p>
    </div>

    <h3 style="margin-bottom: 15px; color: #333;">Citation</h3>
    <div class="paper-citation">@misc{zhang2024eamaentityawaremultimodal,
      title={EAMA : Entity-Aware Multimodal Alignment Based Approach for News Image Captioning},
      author={Junzhe Zhang and Huixuan Zhang and Xunjian Yin and Xiaojun Wan},
      year={2024},
      eprint={2402.19404},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2402.19404},
}</div>
  </main>

  <!-- Footer -->
  <footer class="site-footer" style="max-width:850px;margin:0 auto;padding:20px;">
    <div class="footer-social">
      <a href="https://github.com/Arvid-pku" aria-label="GitHub" target="_blank" rel="noopener">
        <svg xmlns="http://www.w3.org/2000/svg" width="22" height="22" viewBox="0 0 24 24" fill="currentColor"><path d="M12 0c-6.626 0-12 5.373-12 12 0 5.302 3.438 9.8 8.207 11.387.599.111.793-.261.793-.577v-2.234c-3.338.726-4.033-1.416-4.033-1.416-.546-1.387-1.333-1.756-1.333-1.756-1.089-.745.083-.729.083-.729 1.205.084 1.839 1.237 1.839 1.237 1.07 1.834 2.807 1.304 3.492.997.107-.775.418-1.305.762-1.604-2.665-.305-5.467-1.334-5.467-5.931 0-1.311.469-2.381 1.236-3.221-.124-.303-.535-1.524.117-3.176 0 0 1.008-.322 3.301 1.23.957-.266 1.983-.399 3.003-.404 1.02.005 2.047.138 3.006.404 2.291-1.552 3.297-1.23 3.297-1.23.653 1.653.242 2.874.118 3.176.77.84 1.235 1.911 1.235 3.221 0 4.609-2.807 5.624-5.479 5.921.43.372.823 1.102.823 2.222v3.293c0 .319.192.694.801.576 4.765-1.589 8.199-6.086 8.199-11.386 0-6.627-5.373-12-12-12z"/></svg>
      </a>
      <a href="https://www.linkedin.com/in/xunjian-yin-5b40252a5" aria-label="LinkedIn" target="_blank" rel="noopener">
        <svg xmlns="http://www.w3.org/2000/svg" width="22" height="22" viewBox="0 0 24 24" fill="currentColor"><path d="M19 0h-14c-2.761 0-5 2.239-5 5v14c0 2.761 2.239 5 5 5h14c2.762 0 5-2.239 5-5v-14c0-2.761-2.238-5-5-5zm-11 19h-3v-11h3v11zm-1.5-12.268c-.966 0-1.75-.79-1.75-1.764s.784-1.764 1.75-1.764 1.75.79 1.75 1.764-.783 1.764-1.75 1.764zm13.5 12.268h-3v-5.604c0-3.368-4-3.113-4 0v5.604h-3v-11h3v1.765c1.396-2.586 7-2.777 7 2.476v6.759z"/></svg>
      </a>
      <a href="https://x.com/xunjian_yin" aria-label="Twitter" target="_blank" rel="noopener">
        <svg xmlns="http://www.w3.org/2000/svg" width="22" height="22" viewBox="0 0 24 24" fill="currentColor"><path d="M18.244 2.25h3.308l-7.227 8.26 8.502 11.24H16.17l-5.214-6.817L4.99 21.75H1.68l7.73-8.835L1.254 2.25H8.08l4.713 6.231zm-1.161 17.52h1.833L7.084 4.126H5.117z"/></svg>
      </a>
      <a href="https://scholar.google.com/citations?user=PociQ5EAAAAJ" aria-label="Google Scholar" target="_blank" rel="noopener">
        <svg xmlns="http://www.w3.org/2000/svg" width="22" height="22" viewBox="0 0 24 24" fill="currentColor"><path d="M5.242 13.769L0 9.5 12 0l12 9.5-5.242 4.269C17.548 11.249 14.978 9.5 12 9.5c-2.977 0-5.548 1.748-6.758 4.269zM12 10a7 7 0 1 0 0 14 7 7 0 0 0 0-14z"/></svg>
      </a>
    </div>
    <p class="footer-copyright">&copy; 2025 Xunjian Yin. All rights reserved.</p>
  </footer>

  <!-- Back to Top Button -->
  <button id="back-to-top" class="back-to-top" aria-label="Back to top">
    <svg xmlns="http://www.w3.org/2000/svg" width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><polyline points="18 15 12 9 6 15"></polyline></svg>
  </button>

  <script src="../utils.js"></script>
  <script>
    document.addEventListener('DOMContentLoaded', function() {
      initializeDarkMode();
      initializeBackToTop();
    });
  </script>
</body>
</html>
