<!DOCTYPE HTML>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>COrAL: Order-Agnostic Language Modeling</title>
  <link rel="stylesheet" type="text/css" href="../stylesheet.css">
  <link rel="stylesheet" type="text/css" href="../shared-styles.css">
  <link rel="icon" type="image/png" href="../figures/logo.png">
  <style>
    .paper-container { max-width: 850px; margin: 0 auto; padding: 40px 20px; line-height: 1.8; }
    .paper-title { font-size: 32px; font-weight: bold; margin-bottom: 20px; line-height: 1.3; color: #1a1a1a; }
    .paper-authors { font-size: 16px; color: #555; margin-bottom: 8px; }
    .paper-venue { font-size: 15px; color: #888; margin-bottom: 25px; font-style: italic; }
    .paper-links { margin-bottom: 35px; }
    .paper-links a { display: inline-block; padding: 10px 20px; margin-right: 12px; margin-bottom: 10px; background: #2d5a3d; color: white; text-decoration: none; border-radius: 6px; font-size: 14px; font-weight: 500; transition: all 0.2s; }
    .paper-links a:hover { background: #1e3d2a; transform: translateY(-1px); }
    .paper-figure { margin: 40px 0; text-align: center; }
    .paper-figure.hero img { max-width: 100%; width: 650px; }
    .paper-figure.medium img { max-width: 600px; width: 100%; }
    .paper-figure img { border-radius: 10px; box-shadow: 0 4px 20px rgba(0,0,0,0.1); }
    .paper-figure figcaption { font-size: 14px; color: #666; margin-top: 15px; max-width: 650px; margin-left: auto; margin-right: auto; line-height: 1.6; }
    .story-section { margin-bottom: 35px; }
    .story-section h2 { font-size: 22px; color: #2d5a3d; margin-bottom: 15px; font-weight: 600; }
    .story-section p { color: #333; margin-bottom: 15px; text-align: justify; }
    .highlight-box { background: linear-gradient(135deg, #f8faf8 0%, #eef4ee 100%); padding: 25px 30px; border-radius: 10px; margin: 30px 0; border-left: 4px solid #2d5a3d; }
    .highlight-box h3 { margin-top: 0; color: #2d5a3d; font-size: 18px; }
    .highlight-box ul { margin-bottom: 0; padding-left: 20px; }
    .highlight-box li { margin-bottom: 8px; color: #444; }
    .back-link { margin-bottom: 30px; }
    .back-link a { color: #2d5a3d; text-decoration: none; font-weight: 500; font-size: 15px; }
    .back-link a:hover { text-decoration: underline; }
    .paper-citation { background: #f5f5f5; padding: 20px; border-radius: 8px; font-family: 'Monaco', 'Menlo', monospace; font-size: 12px; overflow-x: auto; white-space: pre-wrap; margin-top: 40px; }
    .paper-citation h3 { font-family: inherit; margin-top: 0; margin-bottom: 15px; font-size: 16px; color: #333; }
  </style>
</head>
<body>
  <nav class="nav-buttons">
    <a href="../index.html" class="nav-button">Home</a>
    <a href="../publications.html" class="nav-button">Publications</a>
    <a href="../projects.html" class="nav-button">Projects</a>
    <a href="../blogs.html" class="nav-button">Blogs</a>
  </nav>

  <main class="paper-container">
    <div class="back-link"><a href="../index.html">← Back to Home</a></div>

    <h1 class="paper-title">COrAL: Order-Agnostic Language Modeling for Efficient Iterative Refinement</h1>
    <p class="paper-authors">Yuxi Xie, Anirudh Goyal, Xiaobao Wu, <b>Xunjian Yin</b>, Xiao Xu, Min-Yen Kan, Liangming Pan, William Yang Wang</p>
    <p class="paper-venue">ArXiv Preprint 2024</p>

    <div class="paper-links">
      <a href="https://arxiv.org/abs/2410.09675">Paper</a>
      <a href="https://github.com/YuxiXie/COrAL">Code</a>
    </div>

    <figure class="paper-figure hero">
      <img src="https://arxiv.org/html/2410.09675v1/x1.png" alt="COrAL Performance">
      <figcaption>COrAL achieves better performance-efficiency trade-offs on GSM8K: higher accuracy with lower inference cost compared to traditional autoregressive approaches.</figcaption>
    </figure>

    <div class="story-section">
      <h2>Breaking the Sequential Bottleneck</h2>
      <p>Language models generate text one token at a time, left to right. This sequential constraint is so fundamental that we rarely question it. But it comes with a cost: every token must wait for all previous tokens, making iterative refinement—where models reconsider and improve their outputs—painfully slow.</p>
      <p>What if we could break free from strict left-to-right generation? What if a model could refine multiple positions simultaneously, reasoning about dependencies without the sequential bottleneck?</p>
    </div>

    <div class="story-section">
      <h2>Order-Agnostic Modeling</h2>
      <p>COrAL introduces a fundamentally different approach: Context-wise Order-Agnostic Language Modeling. Instead of predicting only the next token, COrAL models multiple token dependencies within manageable context windows. This allows the model to generate and refine tokens in parallel, capturing diverse dependencies without strict ordering.</p>
      <p>The key insight is that within a local window, the "correct" order of generation isn't always clear—and enforcing one might actually hurt performance. By being agnostic to order, COrAL can choose the most informative generation sequence dynamically.</p>
    </div>

    <figure class="paper-figure medium">
      <img src="https://arxiv.org/html/2410.09675v1/x2.png" alt="Sliding Blockwise Decoding">
      <figcaption>Sliding Blockwise Order-Agnostic Decoding: the model performs multi-token forward prediction and backward reconstruction within sliding windows, enabling parallel iterative refinement.</figcaption>
    </figure>

    <div class="highlight-box">
      <h3>The Technical Innovation</h3>
      <p>We introduce sliding blockwise order-agnostic decoding. The model predicts multiple tokens forward, then reconstructs backward within each window. As the window slides, the model iteratively refines its outputs—all happening in parallel within each block. This achieves the benefits of iterative refinement without the sequential cost.</p>
    </div>

    <div class="story-section">
      <h2>Built Into the Architecture</h2>
      <p>Previous approaches to iterative refinement operated at the prompting or application level—asking models to "think again" or "check your work." COrAL incorporates refinement directly into the architecture. The model doesn't need to be told to reconsider; it naturally refines as part of its generation process.</p>
      <p>This architectural integration means refinement happens efficiently, without the overhead of multiple forward passes or explicit self-correction prompts.</p>
    </div>

    <div class="highlight-box">
      <h3>Key Results</h3>
      <ul>
        <li><b>Efficiency Gains:</b> Parallel generation within blocks reduces inference latency</li>
        <li><b>Better Reasoning:</b> Improved performance on mathematical reasoning tasks like GSM8K</li>
        <li><b>Scalable Refinement:</b> Performance improves with more refinement iterations</li>
        <li><b>Architectural Innovation:</b> Refinement built into the model, not bolted on</li>
      </ul>
    </div>

    <div class="story-section">
      <h2>Looking Forward</h2>
      <p>COrAL challenges the assumption that autoregressive, left-to-right generation is the only way to build language models. By relaxing the ordering constraint within local windows, we unlock new possibilities for efficient iterative refinement—a capability increasingly important as we push models toward more complex reasoning tasks.</p>
    </div>

    <h3 style="margin-bottom: 15px; color: #333;">Citation</h3>
    <div class="paper-citation">@misc{xie2024coralorderagnosticlanguagemodeling,
    title={COrAL: Order-Agnostic Language Modeling for Efficient Iterative Refinement},
    author={Yuxi Xie and Anirudh Goyal and Xiaobao Wu and Xunjian Yin and Xiao Xu and Min-Yen Kan and Liangming Pan and William Yang Wang},
    year={2024},
    eprint={2410.09675},
    archivePrefix={arXiv},
    primaryClass={cs.CL},
    url={https://arxiv.org/abs/2410.09675}
}</div>
  </main>
</body>
</html>
