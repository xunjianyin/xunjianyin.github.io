<!DOCTYPE HTML>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>Self-Generated Documents for RAG</title>
  <link rel="stylesheet" type="text/css" href="../stylesheet.css">
  <link rel="stylesheet" type="text/css" href="../shared-styles.css">
  <link rel="icon" type="image/png" href="../figures/logo.png">
  <style>
    .paper-container { max-width: 850px; margin: 0 auto; padding: 40px 20px; line-height: 1.8; }
    .paper-title { font-size: 32px; font-weight: bold; margin-bottom: 20px; line-height: 1.3; color: #1a1a1a; }
    .paper-authors { font-size: 16px; color: #555; margin-bottom: 8px; }
    .paper-venue { font-size: 15px; color: #888; margin-bottom: 25px; font-style: italic; }
    .paper-links { margin-bottom: 35px; }
    .paper-links a { display: inline-block; padding: 10px 20px; margin-right: 12px; margin-bottom: 10px; background: #2d5a3d; color: white; text-decoration: none; border-radius: 6px; font-size: 14px; font-weight: 500; transition: all 0.2s; }
    .paper-links a:hover { background: #1e3d2a; transform: translateY(-1px); }
    .paper-figure { margin: 40px 0; text-align: center; }
    .paper-figure.hero img { max-width: 100%; width: 700px; }
    .paper-figure.medium img { max-width: 550px; width: 100%; }
    .paper-figure img { border-radius: 10px; box-shadow: 0 4px 20px rgba(0,0,0,0.1); }
    .paper-figure figcaption { font-size: 14px; color: #666; margin-top: 15px; max-width: 650px; margin-left: auto; margin-right: auto; line-height: 1.6; }
    .story-section { margin-bottom: 35px; }
    .story-section h2 { font-size: 22px; color: #2d5a3d; margin-bottom: 15px; font-weight: 600; }
    .story-section p { color: #333; margin-bottom: 15px; text-align: justify; }
    .highlight-box { background: linear-gradient(135deg, #f8faf8 0%, #eef4ee 100%); padding: 25px 30px; border-radius: 10px; margin: 30px 0; border-left: 4px solid #2d5a3d; }
    .highlight-box h3 { margin-top: 0; color: #2d5a3d; font-size: 18px; }
    .highlight-box ul { margin-bottom: 0; padding-left: 20px; }
    .highlight-box li { margin-bottom: 8px; color: #444; }
    .warning-box { background: linear-gradient(135deg, #fff8f0 0%, #ffefe0 100%); padding: 25px 30px; border-radius: 10px; margin: 30px 0; border-left: 4px solid #d35400; }
    .warning-box h3 { margin-top: 0; color: #d35400; font-size: 18px; }
    .back-link { margin-bottom: 30px; }
    .back-link a { color: #2d5a3d; text-decoration: none; font-weight: 500; font-size: 15px; }
    .back-link a:hover { text-decoration: underline; }
    .paper-citation { background: #f5f5f5; padding: 20px; border-radius: 8px; font-family: 'Monaco', 'Menlo', monospace; font-size: 12px; overflow-x: auto; white-space: pre-wrap; margin-top: 40px; }
    .paper-citation h3 { font-family: inherit; margin-top: 0; margin-bottom: 15px; font-size: 16px; color: #333; }

    /* Dark mode styles */
    [data-theme="dark"] .paper-title { color: var(--text-color); }
    [data-theme="dark"] .paper-authors { color: #b8b8b8; }
    [data-theme="dark"] .paper-venue { color: #999; }
    [data-theme="dark"] .story-section h2 { color: var(--primary-color); }
    [data-theme="dark"] .story-section p { color: var(--text-color); }
    [data-theme="dark"] .paper-figure figcaption { color: #b8b8b8; }
    [data-theme="dark"] .highlight-box { background: linear-gradient(135deg, #1a2a1a 0%, #1e3a1e 100%); border-left-color: var(--primary-color); }
    [data-theme="dark"] .highlight-box h3 { color: var(--primary-color); }
    [data-theme="dark"] .highlight-box li, [data-theme="dark"] .highlight-box p { color: var(--text-color); }
    [data-theme="dark"] .back-link a { color: var(--primary-color); }
    [data-theme="dark"] .paper-citation { background: var(--section-bg); color: var(--text-color); }
    [data-theme="dark"] .paper-links a { background: var(--primary-color); }
    [data-theme="dark"] .paper-links a:hover { background: #004a8c; }
  </style>
</head>
<body>
  <nav class="nav-buttons" role="navigation" aria-label="Main navigation">
    <a href="../index.html" class="nav-button">Home</a>
    <a href="../publications.html" class="nav-button">Publications</a>
    <a href="../projects.html" class="nav-button">Projects</a>
    <a href="../blogs.html" class="nav-button">Blogs</a>
    <a href="../photography.html" class="nav-button">Photography</a>
    <button id="theme-toggle" class="theme-toggle" aria-label="Toggle dark mode" title="Toggle dark/light mode"></button>
  </nav>

  <main class="paper-container">
    <div class="back-link"><a href="../index.html">← Back to Home</a></div>

    <h1 class="paper-title">Evaluating Self-Generated Documents for Enhancing Retrieval-Augmented Generation with Large Language Models</h1>
    <p class="paper-authors">Jiatong Shi*, <b>Xunjian Yin*</b>, Xiaojun Wan</p>
    <p class="paper-venue">NAACL 2025 Findings</p>

    <div class="paper-links">
      <a href="https://aclanthology.org/2025.findings-naacl.215/">Paper</a>
    </div>

    <div class="story-section">
      <h2>When Models Write Their Own Context</h2>
      <p>Retrieval-augmented generation (RAG) has become the standard approach for grounding language models in external knowledge. But what if the model could generate its own context? Recent work has explored using self-generated documents as an alternative to retrieval—letting the model write background information before answering.</p>
      <p>The idea is appealing: no need for external databases, no retrieval latency, and the generated context is perfectly tailored to the question. But how reliable is self-generated content? When does it help, and when does it hurt?</p>
    </div>

    <div class="story-section">
      <h2>A Systematic Investigation</h2>
      <p>We conducted the first comprehensive evaluation of self-generated documents in RAG systems. Rather than assuming self-generation is universally helpful or harmful, we sought to understand the factors that determine its effectiveness. What types of tasks benefit? How does model capability matter? When should we trust self-generated content?</p>
    </div>

    <div class="warning-box">
      <h3>The Double-Edged Sword</h3>
      <p>Our findings reveal a nuanced picture. Self-generated documents can improve performance on knowledge-intensive tasks—the model's pre-trained knowledge, when properly elicited, provides useful context. But self-generation also risks introducing hallucinations and factual errors that compound rather than correct the model's limitations.</p>
    </div>

    <div class="story-section">
      <h2>When Self-Generation Works</h2>
      <p>We found that task type matters enormously. For reasoning tasks, where the challenge is organizing and applying knowledge the model already has, self-generated context helps structure thinking. For factual recall tasks, where accuracy depends on specific memorized facts, self-generation is riskier—the model may confidently generate plausible but incorrect information.</p>
      <p>Model capability also plays a crucial role. Larger, more capable models produce more reliable self-generated content. Smaller models are more likely to hallucinate, making self-generation counterproductive.</p>
    </div>

    <div class="highlight-box">
      <h3>Key Findings</h3>
      <ul>
        <li><b>Task Dependency:</b> Self-generation works better for reasoning than factual recall</li>
        <li><b>Model Capability:</b> Larger models produce more reliable self-generated content</li>
        <li><b>Complementary Use:</b> Combining self-generated and retrieved documents often yields best results</li>
        <li><b>Verification Need:</b> Self-generated content requires additional verification to avoid hallucinations</li>
      </ul>
    </div>

    <div class="story-section">
      <h2>Practical Guidelines</h2>
      <p>Based on our analysis, we propose guidelines for practitioners. Self-generation should be used selectively, considering task type and model capability. When factual accuracy is critical, retrieval from verified sources remains essential. But for reasoning and synthesis tasks, self-generated context can be a powerful complement.</p>
      <p>The most robust approach combines both: retrieve external documents for factual grounding, and use self-generation to bridge gaps and structure reasoning.</p>
    </div>

    <h3 style="margin-bottom: 15px; color: #333;">Citation</h3>
    <div class="paper-citation">@inproceedings{shi-yin-2025-evaluating,
    title = "Evaluating Self-Generated Documents for Enhancing Retrieval-Augmented Generation with Large Language Models",
    author = "Shi, Jiatong and Yin, Xunjian and Wan, Xiaojun",
    booktitle = "Findings of the Association for Computational Linguistics: NAACL 2025",
    year = "2025",
    url = "https://aclanthology.org/2025.findings-naacl.215/"
}</div>
  </main>

  <!-- Footer -->
  <footer class="site-footer" style="max-width:850px;margin:0 auto;padding:20px;">
    <div class="footer-social">
      <a href="https://github.com/Arvid-pku" aria-label="GitHub" target="_blank" rel="noopener">
        <svg xmlns="http://www.w3.org/2000/svg" width="22" height="22" viewBox="0 0 24 24" fill="currentColor"><path d="M12 0c-6.626 0-12 5.373-12 12 0 5.302 3.438 9.8 8.207 11.387.599.111.793-.261.793-.577v-2.234c-3.338.726-4.033-1.416-4.033-1.416-.546-1.387-1.333-1.756-1.333-1.756-1.089-.745.083-.729.083-.729 1.205.084 1.839 1.237 1.839 1.237 1.07 1.834 2.807 1.304 3.492.997.107-.775.418-1.305.762-1.604-2.665-.305-5.467-1.334-5.467-5.931 0-1.311.469-2.381 1.236-3.221-.124-.303-.535-1.524.117-3.176 0 0 1.008-.322 3.301 1.23.957-.266 1.983-.399 3.003-.404 1.02.005 2.047.138 3.006.404 2.291-1.552 3.297-1.23 3.297-1.23.653 1.653.242 2.874.118 3.176.77.84 1.235 1.911 1.235 3.221 0 4.609-2.807 5.624-5.479 5.921.43.372.823 1.102.823 2.222v3.293c0 .319.192.694.801.576 4.765-1.589 8.199-6.086 8.199-11.386 0-6.627-5.373-12-12-12z"/></svg>
      </a>
      <a href="https://www.linkedin.com/in/xunjian-yin-5b40252a5" aria-label="LinkedIn" target="_blank" rel="noopener">
        <svg xmlns="http://www.w3.org/2000/svg" width="22" height="22" viewBox="0 0 24 24" fill="currentColor"><path d="M19 0h-14c-2.761 0-5 2.239-5 5v14c0 2.761 2.239 5 5 5h14c2.762 0 5-2.239 5-5v-14c0-2.761-2.238-5-5-5zm-11 19h-3v-11h3v11zm-1.5-12.268c-.966 0-1.75-.79-1.75-1.764s.784-1.764 1.75-1.764 1.75.79 1.75 1.764-.783 1.764-1.75 1.764zm13.5 12.268h-3v-5.604c0-3.368-4-3.113-4 0v5.604h-3v-11h3v1.765c1.396-2.586 7-2.777 7 2.476v6.759z"/></svg>
      </a>
      <a href="https://x.com/xunjian_yin" aria-label="Twitter" target="_blank" rel="noopener">
        <svg xmlns="http://www.w3.org/2000/svg" width="22" height="22" viewBox="0 0 24 24" fill="currentColor"><path d="M18.244 2.25h3.308l-7.227 8.26 8.502 11.24H16.17l-5.214-6.817L4.99 21.75H1.68l7.73-8.835L1.254 2.25H8.08l4.713 6.231zm-1.161 17.52h1.833L7.084 4.126H5.117z"/></svg>
      </a>
      <a href="https://scholar.google.com/citations?user=PociQ5EAAAAJ" aria-label="Google Scholar" target="_blank" rel="noopener">
        <svg xmlns="http://www.w3.org/2000/svg" width="22" height="22" viewBox="0 0 24 24" fill="currentColor"><path d="M5.242 13.769L0 9.5 12 0l12 9.5-5.242 4.269C17.548 11.249 14.978 9.5 12 9.5c-2.977 0-5.548 1.748-6.758 4.269zM12 10a7 7 0 1 0 0 14 7 7 0 0 0 0-14z"/></svg>
      </a>
    </div>
    <p class="footer-copyright">© 2025 Xunjian Yin. All rights reserved.</p>
  </footer>

  <!-- Back to Top Button -->
  <button id="back-to-top" class="back-to-top" aria-label="Back to top">
    <svg xmlns="http://www.w3.org/2000/svg" width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><polyline points="18 15 12 9 6 15"></polyline></svg>
  </button>

  <script src="../utils.js"></script>
  <script>
    document.addEventListener('DOMContentLoaded', function() {
      initializeDarkMode();
      initializeBackToTop();
    });
  </script>
</body>
</html>
